{
  "simulation_num": 2,
  "timestamp": "2025-12-12T20:18:50.859000",
  "set_index": 76,
  "interviewer_model_type": "api",
  "interviewer_model_name": "gpt-4o-mini",
  "company_profile": {
    "id": "COMP077",
    "name": "建設テック株式会社",
    "basic_info": {
      "established": 2018,
      "capital": "30億円",
      "employees": 420,
      "hq": "大阪府大阪市"
    },
    "business": [
      "建設現場DX",
      "3D測量システム",
      "施工管理アプリ"
    ],
    "vision": "テクノロジーで建設業界の生産性を革新する",
    "news": [
      "2025年 AI施工管理で工期短縮30%達成",
      "2024年 3D測量システム建設会社500社導入"
    ],
    "plan": "海外建設プロジェクト参画とロボット施工技術開発",
    "partnerships": [
      "大手建設会社",
      "測量機器メーカー"
    ],
    "advantages": [
      "現場特化技術",
      "施工効率化ノウハウ"
    ],
    "recruit": [
      "建設業界への理解",
      "現場課題解決への意欲"
    ]
  },
  "interview_transcripts": [
    {
      "candidate": "学生MM3",
      "preparation": "low",
      "knowledge_coverage": "5/10 (50%)",
      "conversation_log": [
        {
          "round": 1,
          "question_type": "common",
          "question": "OpenAI APIキーが設定されていません。環境変数OPENAI_API_KEYを設定してください。",
          "answer": "OpenAI APIキーが設定されていません。環境変数OPENAI_API_KEYを設定してください。",
          "token_info": {
            "prompt_tokens": 0,
            "completion_tokens": 0,
            "total_tokens": 0
          }
        },
        {
          "round": 2,
          "question_type": "individual",
          "question": "OpenAI APIキーが設定されていません。環境変数OPENAI_API_KEYを設定してください。",
          "answer": "OpenAI APIキーが設定されていません。環境変数OPENAI_API_KEYを設定してください。",
          "token_info": {
            "prompt_tokens": 0,
            "completion_tokens": 0,
            "total_tokens": 0
          }
        },
        {
          "round": 2,
          "question_type": "individual",
          "question": "OpenAI APIキーが設定されていません。環境変数OPENAI_API_KEYを設定してください。",
          "answer": "OpenAI APIキーが設定されていません。環境変数OPENAI_API_KEYを設定してください。",
          "token_info": {
            "prompt_tokens": 0,
            "completion_tokens": 0,
            "total_tokens": 0
          }
        }
      ]
    },
    {
      "candidate": "学生MM2",
      "preparation": "medium",
      "knowledge_coverage": "7/10 (70%)",
      "conversation_log": [
        {
          "round": 1,
          "question_type": "common",
          "question": "OpenAI APIキーが設定されていません。環境変数OPENAI_API_KEYを設定してください。",
          "answer": "OpenAI APIキーが設定されていません。環境変数OPENAI_API_KEYを設定してください。",
          "token_info": {
            "prompt_tokens": 0,
            "completion_tokens": 0,
            "total_tokens": 0
          }
        },
        {
          "round": 2,
          "question_type": "individual",
          "question": "OpenAI APIキーが設定されていません。環境変数OPENAI_API_KEYを設定してください。",
          "answer": "OpenAI APIキーが設定されていません。環境変数OPENAI_API_KEYを設定してください。",
          "token_info": {
            "prompt_tokens": 0,
            "completion_tokens": 0,
            "total_tokens": 0
          }
        }
      ]
    },
    {
      "candidate": "学生MM1",
      "preparation": "high",
      "knowledge_coverage": "10/10 (100%)",
      "conversation_log": [
        {
          "round": 1,
          "question_type": "common",
          "question": "OpenAI APIキーが設定されていません。環境変数OPENAI_API_KEYを設定してください。",
          "answer": "OpenAI APIキーが設定されていません。環境変数OPENAI_API_KEYを設定してください。",
          "token_info": {
            "prompt_tokens": 0,
            "completion_tokens": 0,
            "total_tokens": 0
          }
        },
        {
          "round": 2,
          "question_type": "individual",
          "question": "OpenAI APIキーが設定されていません。環境変数OPENAI_API_KEYを設定してください。",
          "answer": "OpenAI APIキーが設定されていません。環境変数OPENAI_API_KEYを設定してください。",
          "token_info": {
            "prompt_tokens": 0,
            "completion_tokens": 0,
            "total_tokens": 0
          }
        }
      ]
    }
  ],
  "evaluations": {
    "least_motivated": "OpenAI APIキーが設定されていません。環境変数OPENAI_API_KEYを設定してください。",
    "ranking": "OpenAI APIキーが設定されていません。環境変数OPENAI_API_KEYを設定してください。",
    "knowledge_gaps": {
      "llm_qualitative_analysis": "OpenAI APIキーが設定されていません。環境変数OPENAI_API_KEYを設定してください。",
      "quantitative_performance_metrics": {
        "学生MM3": {
          "metrics": {
            "precision": 0.0,
            "recall": 0.0,
            "accuracy": 0.0,
            "f1_score": 0.0,
            "true_positives": 0,
            "false_positives": 0,
            "false_negatives": 6
          },
          "details": {
            "correctly_detected_gaps (TP)": [],
            "incorrectly_detected_gaps (FP)": [],
            "missed_gaps (FN)": [
              "plan",
              "basic_info",
              "id",
              "advantages",
              "news",
              "partnerships"
            ]
          },
          "note": "LLM output for this candidate was not found or failed to parse."
        },
        "学生MM2": {
          "metrics": {
            "precision": 0.0,
            "recall": 0.0,
            "accuracy": 0.0,
            "f1_score": 0.0,
            "true_positives": 0,
            "false_positives": 0,
            "false_negatives": 4
          },
          "details": {
            "correctly_detected_gaps (TP)": [],
            "incorrectly_detected_gaps (FP)": [],
            "missed_gaps (FN)": [
              "id",
              "basic_info",
              "advantages",
              "recruit"
            ]
          },
          "note": "LLM output for this candidate was not found or failed to parse."
        },
        "学生MM1": {
          "metrics": {
            "precision": 0.0,
            "recall": 0.0,
            "accuracy": 0.0,
            "f1_score": 0.0,
            "true_positives": 0,
            "false_positives": 0,
            "false_negatives": 0
          },
          "details": {
            "correctly_detected_gaps (TP)": [],
            "incorrectly_detected_gaps (FP)": [],
            "missed_gaps (FN)": []
          },
          "note": "LLM output for this candidate was not found or failed to parse."
        }
      }
    }
  },
  "ranking_accuracy": {
    "accuracy": null,
    "is_valid": false,
    "true_ranking": [
      {
        "name": "学生MM3",
        "score": 1,
        "preparation": "low"
      },
      {
        "name": "学生MM2",
        "score": 2,
        "preparation": "medium"
      },
      {
        "name": "学生MM1",
        "score": 3,
        "preparation": "high"
      }
    ],
    "predicted_ranking": [
      "不明",
      "不明",
      "不明"
    ],
    "raw_predicted_ranking": [
      "不明",
      "不明",
      "不明"
    ],
    "message": "ランキングが正しく抽出できませんでした。スコアは計算されません。"
  },
  "knowledge_gaps_metrics": {
    "avg_accuracy": 0.0,
    "avg_f1_score": 0.0,
    "avg_precision": 0.0,
    "avg_recall": 0.0,
    "knowledge_gaps_metrics_by_motivation": {
      "low": 0.0,
      "medium": 0.0,
      "high": 0.0
    },
    "per_candidate_metrics": {
      "学生MM3": {
        "metrics": {
          "precision": 0.0,
          "recall": 0.0,
          "accuracy": 0.0,
          "f1_score": 0.0,
          "true_positives": 0,
          "false_positives": 0,
          "false_negatives": 6
        },
        "details": {
          "correctly_detected_gaps (TP)": [],
          "incorrectly_detected_gaps (FP)": [],
          "missed_gaps (FN)": [
            "plan",
            "basic_info",
            "id",
            "advantages",
            "news",
            "partnerships"
          ]
        },
        "note": "LLM output for this candidate was not found or failed to parse."
      },
      "学生MM2": {
        "metrics": {
          "precision": 0.0,
          "recall": 0.0,
          "accuracy": 0.0,
          "f1_score": 0.0,
          "true_positives": 0,
          "false_positives": 0,
          "false_negatives": 4
        },
        "details": {
          "correctly_detected_gaps (TP)": [],
          "incorrectly_detected_gaps (FP)": [],
          "missed_gaps (FN)": [
            "id",
            "basic_info",
            "advantages",
            "recruit"
          ]
        },
        "note": "LLM output for this candidate was not found or failed to parse."
      },
      "学生MM1": {
        "metrics": {
          "precision": 0.0,
          "recall": 0.0,
          "accuracy": 0.0,
          "f1_score": 0.0,
          "true_positives": 0,
          "false_positives": 0,
          "false_negatives": 0
        },
        "details": {
          "correctly_detected_gaps (TP)": [],
          "incorrectly_detected_gaps (FP)": [],
          "missed_gaps (FN)": []
        },
        "note": "LLM output for this candidate was not found or failed to parse."
      }
    }
  },
  "eval1_hits": {
    "1": 0,
    "2": 0
  },
  "eval2_perfect_matches": {
    "1": 0,
    "2": 0
  },
  "eval1_hits_series": [
    0,
    0
  ],
  "eval2_hits_series": [
    0,
    0
  ],
  "eval3_accuracy_series": [
    0.0,
    0.0
  ],
  "eval3_f1_series": [
    0.0,
    0.0
  ],
  "token_usage": {
    "prompt_tokens": 0,
    "completion_tokens": 0,
    "total_tokens": 0
  },
  "round_evaluations": [
    {
      "round": 1,
      "question_type": "common",
      "evaluations": {
        "least_motivated": "OpenAI APIキーが設定されていません。環境変数OPENAI_API_KEYを設定してください。",
        "ranking": "OpenAI APIキーが設定されていません。環境変数OPENAI_API_KEYを設定してください。",
        "knowledge_gaps": {
          "llm_qualitative_analysis": "OpenAI APIキーが設定されていません。環境変数OPENAI_API_KEYを設定してください。",
          "quantitative_performance_metrics": {
            "学生MM3": {
              "metrics": {
                "precision": 0.0,
                "recall": 0.0,
                "accuracy": 0.0,
                "f1_score": 0.0,
                "true_positives": 0,
                "false_positives": 0,
                "false_negatives": 6
              },
              "details": {
                "correctly_detected_gaps (TP)": [],
                "incorrectly_detected_gaps (FP)": [],
                "missed_gaps (FN)": [
                  "plan",
                  "basic_info",
                  "id",
                  "advantages",
                  "news",
                  "partnerships"
                ]
              },
              "note": "LLM output for this candidate was not found or failed to parse."
            },
            "学生MM2": {
              "metrics": {
                "precision": 0.0,
                "recall": 0.0,
                "accuracy": 0.0,
                "f1_score": 0.0,
                "true_positives": 0,
                "false_positives": 0,
                "false_negatives": 4
              },
              "details": {
                "correctly_detected_gaps (TP)": [],
                "incorrectly_detected_gaps (FP)": [],
                "missed_gaps (FN)": [
                  "id",
                  "basic_info",
                  "advantages",
                  "recruit"
                ]
              },
              "note": "LLM output for this candidate was not found or failed to parse."
            },
            "学生MM1": {
              "metrics": {
                "precision": 0.0,
                "recall": 0.0,
                "accuracy": 0.0,
                "f1_score": 0.0,
                "true_positives": 0,
                "false_positives": 0,
                "false_negatives": 0
              },
              "details": {
                "correctly_detected_gaps (TP)": [],
                "incorrectly_detected_gaps (FP)": [],
                "missed_gaps (FN)": []
              },
              "note": "LLM output for this candidate was not found or failed to parse."
            }
          }
        }
      },
      "eval1_hit": 0,
      "eval2_perfect_match": 0,
      "ranking_accuracy": {
        "accuracy": null,
        "is_valid": false,
        "true_ranking": [
          {
            "name": "学生MM3",
            "score": 1,
            "preparation": "low"
          },
          {
            "name": "学生MM2",
            "score": 2,
            "preparation": "medium"
          },
          {
            "name": "学生MM1",
            "score": 3,
            "preparation": "high"
          }
        ],
        "predicted_ranking": [
          "不明",
          "不明",
          "不明"
        ],
        "raw_predicted_ranking": [
          "不明",
          "不明",
          "不明"
        ],
        "message": "ランキングが正しく抽出できませんでした。スコアは計算されません。"
      },
      "knowledge_gaps_metrics": {
        "avg_accuracy": 0.0,
        "avg_f1_score": 0.0,
        "avg_precision": 0.0,
        "avg_recall": 0.0,
        "knowledge_gaps_metrics_by_motivation": {
          "low": 0.0,
          "medium": 0.0,
          "high": 0.0
        },
        "per_candidate_metrics": {
          "学生MM3": {
            "metrics": {
              "precision": 0.0,
              "recall": 0.0,
              "accuracy": 0.0,
              "f1_score": 0.0,
              "true_positives": 0,
              "false_positives": 0,
              "false_negatives": 6
            },
            "details": {
              "correctly_detected_gaps (TP)": [],
              "incorrectly_detected_gaps (FP)": [],
              "missed_gaps (FN)": [
                "plan",
                "basic_info",
                "id",
                "advantages",
                "news",
                "partnerships"
              ]
            },
            "note": "LLM output for this candidate was not found or failed to parse."
          },
          "学生MM2": {
            "metrics": {
              "precision": 0.0,
              "recall": 0.0,
              "accuracy": 0.0,
              "f1_score": 0.0,
              "true_positives": 0,
              "false_positives": 0,
              "false_negatives": 4
            },
            "details": {
              "correctly_detected_gaps (TP)": [],
              "incorrectly_detected_gaps (FP)": [],
              "missed_gaps (FN)": [
                "id",
                "basic_info",
                "advantages",
                "recruit"
              ]
            },
            "note": "LLM output for this candidate was not found or failed to parse."
          },
          "学生MM1": {
            "metrics": {
              "precision": 0.0,
              "recall": 0.0,
              "accuracy": 0.0,
              "f1_score": 0.0,
              "true_positives": 0,
              "false_positives": 0,
              "false_negatives": 0
            },
            "details": {
              "correctly_detected_gaps (TP)": [],
              "incorrectly_detected_gaps (FP)": [],
              "missed_gaps (FN)": []
            },
            "note": "LLM output for this candidate was not found or failed to parse."
          }
        }
      }
    },
    {
      "round": 2,
      "question_type": "individual",
      "target_candidate": "学生MM3",
      "evaluations": {
        "least_motivated": "OpenAI APIキーが設定されていません。環境変数OPENAI_API_KEYを設定してください。",
        "ranking": "OpenAI APIキーが設定されていません。環境変数OPENAI_API_KEYを設定してください。",
        "knowledge_gaps": {
          "llm_qualitative_analysis": "OpenAI APIキーが設定されていません。環境変数OPENAI_API_KEYを設定してください。",
          "quantitative_performance_metrics": {
            "学生MM3": {
              "metrics": {
                "precision": 0.0,
                "recall": 0.0,
                "accuracy": 0.0,
                "f1_score": 0.0,
                "true_positives": 0,
                "false_positives": 0,
                "false_negatives": 6
              },
              "details": {
                "correctly_detected_gaps (TP)": [],
                "incorrectly_detected_gaps (FP)": [],
                "missed_gaps (FN)": [
                  "plan",
                  "basic_info",
                  "id",
                  "advantages",
                  "news",
                  "partnerships"
                ]
              },
              "note": "LLM output for this candidate was not found or failed to parse."
            },
            "学生MM2": {
              "metrics": {
                "precision": 0.0,
                "recall": 0.0,
                "accuracy": 0.0,
                "f1_score": 0.0,
                "true_positives": 0,
                "false_positives": 0,
                "false_negatives": 4
              },
              "details": {
                "correctly_detected_gaps (TP)": [],
                "incorrectly_detected_gaps (FP)": [],
                "missed_gaps (FN)": [
                  "id",
                  "basic_info",
                  "advantages",
                  "recruit"
                ]
              },
              "note": "LLM output for this candidate was not found or failed to parse."
            },
            "学生MM1": {
              "metrics": {
                "precision": 0.0,
                "recall": 0.0,
                "accuracy": 0.0,
                "f1_score": 0.0,
                "true_positives": 0,
                "false_positives": 0,
                "false_negatives": 0
              },
              "details": {
                "correctly_detected_gaps (TP)": [],
                "incorrectly_detected_gaps (FP)": [],
                "missed_gaps (FN)": []
              },
              "note": "LLM output for this candidate was not found or failed to parse."
            }
          }
        }
      },
      "eval1_hit": 0,
      "eval2_perfect_match": 0,
      "ranking_accuracy": {
        "accuracy": null,
        "is_valid": false,
        "true_ranking": [
          {
            "name": "学生MM3",
            "score": 1,
            "preparation": "low"
          },
          {
            "name": "学生MM2",
            "score": 2,
            "preparation": "medium"
          },
          {
            "name": "学生MM1",
            "score": 3,
            "preparation": "high"
          }
        ],
        "predicted_ranking": [
          "不明",
          "不明",
          "不明"
        ],
        "raw_predicted_ranking": [
          "不明",
          "不明",
          "不明"
        ],
        "message": "ランキングが正しく抽出できませんでした。スコアは計算されません。"
      },
      "knowledge_gaps_metrics": {
        "avg_accuracy": 0.0,
        "avg_f1_score": 0.0,
        "avg_precision": 0.0,
        "avg_recall": 0.0,
        "knowledge_gaps_metrics_by_motivation": {
          "low": 0.0,
          "medium": 0.0,
          "high": 0.0
        },
        "per_candidate_metrics": {
          "学生MM3": {
            "metrics": {
              "precision": 0.0,
              "recall": 0.0,
              "accuracy": 0.0,
              "f1_score": 0.0,
              "true_positives": 0,
              "false_positives": 0,
              "false_negatives": 6
            },
            "details": {
              "correctly_detected_gaps (TP)": [],
              "incorrectly_detected_gaps (FP)": [],
              "missed_gaps (FN)": [
                "plan",
                "basic_info",
                "id",
                "advantages",
                "news",
                "partnerships"
              ]
            },
            "note": "LLM output for this candidate was not found or failed to parse."
          },
          "学生MM2": {
            "metrics": {
              "precision": 0.0,
              "recall": 0.0,
              "accuracy": 0.0,
              "f1_score": 0.0,
              "true_positives": 0,
              "false_positives": 0,
              "false_negatives": 4
            },
            "details": {
              "correctly_detected_gaps (TP)": [],
              "incorrectly_detected_gaps (FP)": [],
              "missed_gaps (FN)": [
                "id",
                "basic_info",
                "advantages",
                "recruit"
              ]
            },
            "note": "LLM output for this candidate was not found or failed to parse."
          },
          "学生MM1": {
            "metrics": {
              "precision": 0.0,
              "recall": 0.0,
              "accuracy": 0.0,
              "f1_score": 0.0,
              "true_positives": 0,
              "false_positives": 0,
              "false_negatives": 0
            },
            "details": {
              "correctly_detected_gaps (TP)": [],
              "incorrectly_detected_gaps (FP)": [],
              "missed_gaps (FN)": []
            },
            "note": "LLM output for this candidate was not found or failed to parse."
          }
        }
      }
    }
  ]
}